<!doctype html>
<html lang="de">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="simple.css" rel="stylesheet">
    <title>KI-Lerntag OSZ Gesundheit</title>
  </head>
  <body>

  <header>
    <h1>Lerntag zu Künstlicher Intelligenz (KI)</h1>
    <p>OSZ Gesundheit Berlin | 29. August 2024</p>
    <nav>
      <ul>
        <li><a href="index.html">👋 Start</a></li>
        <li><a href="angebote.html">🗨️ Angebote</a></li>
        <li><a href="stationen.html">💡 Stationen</a></li>
        <li><a href="vertiefung.html">❗ Vertiefung</a></li>
      </ul>
    </nav>
  </header>

  <main>
    <h2>Station 8: Bias und KI</h2>
    
    <h3>Worum geht es hier?</h3>
    <p>KI-generierte Inhalte sind zwangsläufig immer Bias-behaftet, denn KI-Tools reproduzieren die Vergangenheit. Stereotype, Diskriminierungen und Vorurteile, die es in den letzten Jahrzehnten in unserer Gesellschaft gab und weiterhin gibt, finden sich vor diesem Hintergrund in den Trainingsdaten und damit auch im Output der vorherrschenden KI-Tools wieder. Wer mit KI-Tools arbeitet, muss dazu einen Umgang finden.</p>

    <h3>Was können wir nutzen?</h3>
    <p>Um sich Bias in KI bewusst zu machen, sind Bildgenerierungstools ein guter Einstieg zum Erkunden. Du kannst zum Beispiel den Prompt nutzen: Eine Person, die auf einer Konferenz redet. Wahrscheinlich wirst du in diesem Fall überwiegend Bilder von weißen, redenden Männern erhalten. Denn das sind die Personen, die es in den Trainingsdaten überwiegend redend auf Konferenzen gibt.</p>
    <p>Wir haben aber natürlich den Anspruch, dass auch Frauen, schwarze Menschen oder Menschen im Rollstuhl redende Personen auf einer Konferenz sein sollten. Und wir möchten gerne, dass dieses Ziel (was oft ja auch schon eine reale Möglichkeit ist) in Bildern entsprechend dargestellt wird, um z.B. auch entsprechende Vorbilder zu bieten.</p>
    <p>Der einfachste Umgang mit dieser Schwierigkeit ist deshalb, in den Eingaben gezielt auf Vielfalt hinzuwirken, z.B. in dem ich in dem Beispiel schreiben würde: eine schwarze Frau, die auf einer Konferenz redet. Oft hilft auch der Beisatz 'divers'.</p>
    <p>Alle Probleme sind damit aber nicht gelöst, denn manchmal gibt es in den Trainingsdaten schlichtweg so wenig Inhalte, dass trotz entsprechendem Prompting das KI-Modell auf die Mehrheits-Darstellung zurückfällt. Diese Herausforderung habe ich im Blogbeitrag <a href="https://ebildungslabor.de/blog/besseres-prompting-hilft-nur-bedingt-gegen-bias/" target="_blank">Besseres Prompting hilft nur bedingt gegen Bias</a> vorgestellt.</p>

    <h3>Wie können wir vorgehen?</h3>
    <p>Macht eigene Erkundungen zu KI und Bias. In Sprachmodellen könnt ihr z.B. beobachten, mit welchen Eigenschaften Frauen und mit welchen Eigenschaften Männer in Texten überwiegend dargestellt werden. All das geschieht sehr subtil. Der erste Schritt zur Veränderung ist ein bewusster Umgang damit. Eine abschließende Lösung gibt es zu dieser Herausforderung nicht.</p>

    <p>Viel Erfolg bei der kritischen Auseinandersetzung mit Bias und KI! 🙂</p>
    
    <p><a href="stationen.html"><button>> Zur Übersicht der Stationen</button></a></p>
  </main>

  <footer>
    <p>Verantwortlich für diese Website ist Nele Hirsch (<a href="https://ebildungslabor.de" target="_blank">eBildungslabor</a>)</p>
    <p>Die Inhalte bleiben auch nach Ablauf unserer Veranstaltung online und können gerne weiter genutzt werden.</p>
  </footer>

  </body>
</html>
