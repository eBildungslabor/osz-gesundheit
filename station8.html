<!doctype html>
<html lang="de">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="simple.css" rel="stylesheet">
    <title>KI-Lerntag OSZ Gesundheit</title>
  </head>
  <body>

  <header>
    <h1>Lerntag zu KÃ¼nstlicher Intelligenz (KI)</h1>
    <p>OSZ Gesundheit Berlin | 29. August 2024</p>
    <nav>
      <ul>
        <li><a href="index.html">ğŸ‘‹ Start</a></li>
        <li><a href="angebote.html">ğŸ—¨ï¸ Angebote</a></li>
        <li><a href="stationen.html">ğŸ’¡ Stationen</a></li>
        <li><a href="vertiefung.html">â— Vertiefung</a></li>
      </ul>
    </nav>
  </header>

  <main>
    <h2>Station 8: Bias und KI</h2>
    
    <h3>Worum geht es hier?</h3>
    <p>KI-generierte Inhalte sind zwangslÃ¤ufig immer Bias-behaftet, denn KI-Tools reproduzieren die Vergangenheit. Stereotype, Diskriminierungen und Vorurteile, die es in den letzten Jahrzehnten in unserer Gesellschaft gab und weiterhin gibt, finden sich vor diesem Hintergrund in den Trainingsdaten und damit auch im Output der vorherrschenden KI-Tools wieder. Wer mit KI-Tools arbeitet, muss dazu einen Umgang finden.</p>

    <h3>Was kÃ¶nnen wir nutzen?</h3>
    <p>Um sich Bias in KI bewusst zu machen, sind Bildgenerierungstools ein guter Einstieg zum Erkunden. Du kannst zum Beispiel den Prompt nutzen: Eine Person, die auf einer Konferenz redet. Wahrscheinlich wirst du in diesem Fall Ã¼berwiegend Bilder von weiÃŸen, redenden MÃ¤nnern erhalten. Denn das sind die Personen, die es in den Trainingsdaten Ã¼berwiegend redend auf Konferenzen gibt.</p>
    <p>Wir haben aber natÃ¼rlich den Anspruch, dass auch Frauen, schwarze Menschen oder Menschen im Rollstuhl redende Personen auf einer Konferenz sein sollten. Und wir mÃ¶chten gerne, dass dieses Ziel (was oft ja auch schon eine reale MÃ¶glichkeit ist) in Bildern entsprechend dargestellt wird, um z.B. auch entsprechende Vorbilder zu bieten.</p>
    <p>Der einfachste Umgang mit dieser Schwierigkeit ist deshalb, in den Eingaben gezielt auf Vielfalt hinzuwirken, z.B. in dem ich in dem Beispiel schreiben wÃ¼rde: eine schwarze Frau, die auf einer Konferenz redet. Oft hilft auch der Beisatz 'divers'.</p>
    <p>Alle Probleme sind damit aber nicht gelÃ¶st, denn manchmal gibt es in den Trainingsdaten schlichtweg so wenig Inhalte, dass trotz entsprechendem Prompting das KI-Modell auf die Mehrheits-Darstellung zurÃ¼ckfÃ¤llt. Diese Herausforderung habe ich im Blogbeitrag <a href="https://ebildungslabor.de/blog/besseres-prompting-hilft-nur-bedingt-gegen-bias/" target="_blank">Besseres Prompting hilft nur bedingt gegen Bias</a> vorgestellt.</p>

    <h3>Wie kÃ¶nnen wir vorgehen?</h3>
    <p>Macht eigene Erkundungen zu KI und Bias. In Sprachmodellen kÃ¶nnt ihr z.B. beobachten, mit welchen Eigenschaften Frauen und mit welchen Eigenschaften MÃ¤nner in Texten Ã¼berwiegend dargestellt werden. All das geschieht sehr subtil. Der erste Schritt zur VerÃ¤nderung ist ein bewusster Umgang damit. Eine abschlieÃŸende LÃ¶sung gibt es zu dieser Herausforderung nicht.</p>

    <p>Viel Erfolg bei der kritischen Auseinandersetzung mit Bias und KI! ğŸ™‚</p>
    
    <p><a href="stationen.html"><button>> Zur Ãœbersicht der Stationen</button></a></p>
  </main>

  <footer>
    <p>Verantwortlich fÃ¼r diese Website ist Nele Hirsch (<a href="https://ebildungslabor.de" target="_blank">eBildungslabor</a>)</p>
    <p>Die Inhalte bleiben auch nach Ablauf unserer Veranstaltung online und kÃ¶nnen gerne weiter genutzt werden.</p>
  </footer>

  </body>
</html>
